{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from random import randrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('Image1A.png', cv2.IMREAD_COLOR)\n",
    "img1_gray = cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY)\n",
    "img2 = cv2.imread('Image1B.png', cv2.IMREAD_COLOR)\n",
    "img2_gray = cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "orb = cv2.ORB_create(1000) \n",
    "\n",
    "keypoints1, descriptors1 = orb.detectAndCompute(img1,None)\n",
    "keypoints2, descriptors2 = orb.detectAndCompute(img2,None)\n",
    "\n",
    "matcher = cv2.BFMatcher(cv2.NORM_HAMMING)\n",
    "raw_matches = matcher.knnMatch(descriptors1, descriptors2, k=2)\n",
    "good_points = []\n",
    "good=[]\n",
    "for m1, m2 in raw_matches:\n",
    "    if m1.distance < 0.6 * m2.distance:\n",
    "        good_points.append((m1.trainIdx, m1.queryIdx))\n",
    "        good.append([m1])\n",
    "img3 = cv2.drawMatchesKnn(img1, keypoints1, img2, keypoints2, good, None, flags=2)\n",
    "\n",
    "\n",
    "scale_percent = 100 # percent of original size\n",
    "width = int(img3.shape[1] * scale_percent / 100)\n",
    "height = int(img3.shape[0] * scale_percent / 100)\n",
    "dim = (width, height)\n",
    "\n",
    "# resize image\n",
    "img3 = cv2.resize(img3, dim, interpolation = cv2.INTER_AREA)\n",
    "cv2.imwrite('Feature_Matched_Image.png', img3)\n",
    "\n",
    "\n",
    "good1 = []\n",
    "for m, n in raw_matches:\n",
    "    if m.distance < 0.6 * n.distance:\n",
    "        good1.append(m)\n",
    "\n",
    "\n",
    "def warpImages(img1, img2, H):\n",
    "\n",
    "    rows1, cols1 = img1.shape[:2]\n",
    "    rows2, cols2 = img2.shape[:2]\n",
    "\n",
    "    list_of_points_1 = np.float32([[0,0], [0, rows1],[cols1, rows1], [cols1, 0]]).reshape(-1, 1, 2)\n",
    "    temp_points = np.float32([[0,0], [0,rows2], [cols2,rows2], [cols2,0]]).reshape(-1,1,2)\n",
    "\n",
    "\n",
    "    list_of_points_2 = cv2.perspectiveTransform(temp_points, H)\n",
    "\n",
    "    list_of_points = np.concatenate((list_of_points_1,list_of_points_2), axis=0)\n",
    "\n",
    "    [x_min, y_min] = np.int32(list_of_points.min(axis=0).ravel() - 0.5)\n",
    "    [x_max, y_max] = np.int32(list_of_points.max(axis=0).ravel() + 0.5)\n",
    "\n",
    "    translation_dist = [-x_min,-y_min]\n",
    "\n",
    "    H_translation = np.array([[1, 0, translation_dist[0]], [0, 1, translation_dist[1]], [0, 0, 1]])\n",
    "\n",
    "    output_img = cv2.warpPerspective(img2, H_translation.dot(H), (x_max-x_min, y_max-y_min))\n",
    "    output_img[translation_dist[1]:rows1+translation_dist[1], translation_dist[0]:cols1+translation_dist[0]] = img1\n",
    "\n",
    "    return output_img\n",
    "\n",
    "\n",
    "MIN_MATCH_COUNT = 10\n",
    "\n",
    "if len(good) > MIN_MATCH_COUNT:\n",
    "    # Convert keypoints to an argument for findHomography\n",
    "    src_pts = np.float32([ keypoints1[m.queryIdx].pt for m in good1]).reshape(-1,1,2)\n",
    "    dst_pts = np.float32([ keypoints2[m.trainIdx].pt for m in good1]).reshape(-1,1,2)\n",
    "\n",
    "    # Establish a homography\n",
    "    M, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "\n",
    "    \n",
    "    result = warpImages(img2, img1, M)\n",
    "\n",
    "    scale_percent = 100 # percent of original size\n",
    "    width = int(img3.shape[1] * scale_percent / 100)\n",
    "    height = int(img3.shape[0] * scale_percent / 100)\n",
    "    dim = (width, height)\n",
    "\n",
    "    # resize image\n",
    "    result = cv2.resize(result, dim, interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "#     cv2.imshow(\"Result\",result)\n",
    "    cv2.imwrite('Stitched_Image.png', result)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting up YOLO for Object Detection ###\n",
    "\n",
    "def get_output_layers(net):\n",
    "    \n",
    "    layer_names = net.getLayerNames()\n",
    "    \n",
    "    output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "    return output_layers\n",
    "\n",
    "\n",
    "def draw_prediction(img, class_id, confidence, x, y, x_plus_w, y_plus_h):\n",
    "\n",
    "    label = str(classes[class_id])\n",
    "\n",
    "    color = COLORS[class_id]\n",
    "\n",
    "    cv2.rectangle(img, (x,y), (x_plus_w,y_plus_h), color, 2)\n",
    "\n",
    "    cv2.putText(img, label, (x-10,y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "classes = None\n",
    "\n",
    "with open(\"yolov3.txt\", 'r') as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "COLORS = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pecentage occupancy: 6.163109243697479\n"
     ]
    }
   ],
   "source": [
    "### Vehicle Detection Using YOLO ###\n",
    "\n",
    "img = cv2.imread(\"Stitched_Image.png\")\n",
    "dim = (800, 700)\n",
    "  \n",
    "# resize image\n",
    "image = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "Width = image.shape[1]\n",
    "Height = image.shape[0]\n",
    "scale = 0.00392\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(image, scale, (416,416), (0,0,0), True, crop=False)\n",
    "\n",
    "net.setInput(blob)\n",
    "\n",
    "outs = net.forward(get_output_layers(net))\n",
    "\n",
    "class_ids = []\n",
    "confidences = []\n",
    "boxes = []\n",
    "conf_threshold = 0.5\n",
    "nms_threshold = 0.4\n",
    "\n",
    "\n",
    "for out in outs:\n",
    "    for detection in out:\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "        if confidence > 0.5:\n",
    "            center_x = int(detection[0] * Width)\n",
    "            center_y = int(detection[1] * Height)\n",
    "            w = int(detection[2] * Width)\n",
    "            h = int(detection[3] * Height)\n",
    "            x = center_x - w / 2\n",
    "            y = center_y - h / 2\n",
    "            class_ids.append(class_id)\n",
    "            confidences.append(float(confidence))\n",
    "            boxes.append([x, y, w, h])\n",
    "\n",
    "\n",
    "indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
    "\n",
    "# Defining Counters\n",
    "bicycles = 0\n",
    "cars = 0\n",
    "motorcycles = 0\n",
    "buses = 0\n",
    "trucks = 0\n",
    "areas = boxes\n",
    "total_area = 0\n",
    "road_area = Width*Height*0.85\n",
    "\n",
    "for i in indices:\n",
    "    i = i[0]\n",
    "    box = boxes[i]\n",
    "    x = box[0]\n",
    "    y = box[1]\n",
    "    w = box[2]\n",
    "    h = box[3]\n",
    "    areas[i] = w*h*0.9\n",
    "    if (class_ids[i] == 1):\n",
    "        bicycles += 1\n",
    "        total_area += areas[i]\n",
    "    if (class_ids[i] == 2):\n",
    "        cars += 1\n",
    "        total_area += areas[i]\n",
    "    if (class_ids[i] == 3):\n",
    "        motorcycles += 1\n",
    "        total_area += areas[i]\n",
    "    if (class_ids[i] == 5):\n",
    "        buses += 1\n",
    "        total_area += areas[i]\n",
    "    if (class_ids[i] == 7):\n",
    "        trucks += 1\n",
    "        total_area += areas[i]\n",
    "    draw_prediction(image, class_ids[i], confidences[i], round(x), round(y), round(x+w), round(y+h))\n",
    "\n",
    "occupancy = (total_area/road_area)*100\n",
    "\n",
    "print(\"pecentage occupancy: \"+ \"{}\".format(occupancy))\n",
    "\n",
    "cv2.imshow(\"object detection\", image)\n",
    "cv2.waitKey()\n",
    "    \n",
    "cv2.imwrite(\"object-detection.jpg\", image)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "### Motion Detection using Image Subtraction ###\n",
    "\n",
    "image1 = cv2.imread(\"Image1A.png\")\n",
    "image2 = cv2.imread(\"Image1B.png\")\n",
    "\n",
    "img_1 = cv2.imread(\"Image1A.png\", 0)\n",
    "img_2 = cv2.imread(\"Image1B.png\", 0)\n",
    "\n",
    "#REFERENCE IMAGE FOR SUBTRACTION\n",
    "reference = img_1\n",
    "\n",
    "#GRAYSCALE CONVERSION AND NOISE REMOVAL\n",
    "background = cv2.GaussianBlur(reference, (21,21), 0)\n",
    "gray = cv2.GaussianBlur(img_2, (21,21), 0)\n",
    "\n",
    "#SUBTRACTION\n",
    "subtraction = cv2.absdiff(background, gray)\n",
    "\n",
    "#APPLICATION OF THRESHOLD\n",
    "threshold = cv2.threshold(subtraction, 55, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "#CONTOUR DETECTION \n",
    "contouring = threshold.copy()\n",
    "contours, hierarchy = cv2.findContours(threshold, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#REMOVING SMALL CONTOURS\n",
    "for c in contours:\n",
    "    if cv2.contourArea(c) < 200:  #removing smallest contours \n",
    "        continue\n",
    "    (x,y,w,h) = cv2.boundingRect(c) #obtaining bounds of the contour \n",
    "  #drawing rectangle of bounds\n",
    "#   cv2.rectangle(frame, (x,y), (x+w, y+h), (0,255,0), 2)\n",
    "\n",
    "cv2.imshow('Feature Matched Image', img3)\n",
    "cv2.imshow('Stitched Image', result)\n",
    "cv2.imshow('image1', image1)\n",
    "cv2.imwrite('motion1.png', image1)\n",
    "cv2.imwrite('motion2.png', image2)\n",
    "cv2.imshow('image2', image2)\n",
    "# cv2.imshow('s',subtraction)\n",
    "cv2.imshow('threshold', threshold)\n",
    "cv2.imwrite('motion_flow.png', threshold)\n",
    "\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
